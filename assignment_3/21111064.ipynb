{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RyE9fJ9gCh0g"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ioPaYllLDolJ"
   },
   "outputs": [],
   "source": [
    "a = open(\"data_banknote_authentication.txt\")\n",
    "line = a.readlines()\n",
    "data = []\n",
    "\n",
    "#cleaning and formation data\n",
    "for i in line:\n",
    "    string = i.replace('\\n','')\n",
    "    string = string.split(',')\n",
    "    data.append(string)\n",
    "data = pd.DataFrame(data)\n",
    "data.columns = ['variance','skewness','curtosis','entropy','class']\n",
    "\n",
    "#repalcing 0 with -1 and dropping the duplicaties\n",
    "data['class'].replace(to_replace=['0'],value='-1',inplace=True)\n",
    "data.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing data into test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y3-vWQ0EWeo"
   },
   "outputs": [],
   "source": [
    "#converting data to numpy array\n",
    "temp = data.to_numpy().astype(float)\n",
    "\n",
    "#shuffling and dividing into train and test set \n",
    "np.random.shuffle(temp)\n",
    "train_x = temp[:1000, :4]\n",
    "train_y = temp[:1000 ,-1]\n",
    "test_x = temp[1000: ,:4]\n",
    "test_y = temp[1000: ,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 \n",
    "Funtion for perceptron and for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CJyRGMZGKiL"
   },
   "outputs": [],
   "source": [
    "#pecptron funtion\n",
    "def perceptron(x,y,size=4,l_rate=1):\n",
    "    w = np.ones(size)\n",
    "    i = 0\n",
    "    while True:\n",
    "        i = i+1 \n",
    "        d = len(x)\n",
    "        #radomly select any data\n",
    "        sel = np.random.randint(0,d)\n",
    "        val = y[sel]*((w*x[sel]).sum())\n",
    "        if val < 0:\n",
    "            #update the value of weights\n",
    "            w = w + l_rate*y[sel]*x[sel]\n",
    "            i = 0   \n",
    "        # convergence condition    \n",
    "        if i > 100:    \n",
    "            return w\n",
    "\n",
    "#funtion prediction of given value\n",
    "def pred(x,w):\n",
    "    predict = np.dot(x,w)\n",
    "    if predict > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "#accuracy \n",
    "def acc(predicted_y,actual_y):\n",
    "    c = 0\n",
    "    for i in range(len(predicted_y)):\n",
    "        if predicted_y[i] == actual_y[i]:\n",
    "            c=c+1\n",
    "    return (c/len(predicted_y))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKAvKcqIiwcO",
    "outputId": "495c661c-36a2-404b-911a-f420902edab1"
   },
   "outputs": [],
   "source": [
    "#training model\n",
    "w = perceptron(train_x,train_y)\n",
    "\n",
    "#accuracy of model\n",
    "p  = []\n",
    "for i in train_x:\n",
    "    p.append(pred(i,w))\n",
    "print(acc(p,train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NT15ypY4j1_"
   },
   "outputs": [],
   "source": [
    "#spliting data for k-fold cross validation\n",
    "x_split = np.split(train_x,10)\n",
    "y_split = np.split(train_y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error on k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH6F_Ngz49fh",
    "outputId": "fc95dd81-1135-42d4-adbd-a621900d052f"
   },
   "outputs": [],
   "source": [
    "min_error = 10\n",
    "\n",
    "#performing k-fold cross validation on 0.1 to 1 as learning rate\n",
    "for k in range(1,11):\n",
    "    w_current = 0\n",
    "    sum = 0\n",
    "   \n",
    "    for i in range(10):\n",
    "        cross_x = np.concatenate(x_split[:i]+x_split[i+1:])\n",
    "        cross_y = np.concatenate(y_split[:i]+y_split[i+1:])\n",
    "        val_x = x_split[i]\n",
    "        val_y = y_split[i]\n",
    "        w = perceptron(cross_x,cross_y,l_rate=k*0.1)\n",
    "        y_pred = []\n",
    "        for j in range(len(val_x)):\n",
    "            y_pred.append(pred(val_x[j],w))\n",
    "        sum = sum + (100-acc(y_pred,val_y))\n",
    "        w_current = w + w_current\n",
    "    \n",
    "    #print error - learning rate, error\n",
    "    print(round(k*0.1,1),sum/10)\n",
    "    w_current = w_current/10\n",
    "\n",
    "    #updating the optimal weights\n",
    "    if sum/10 < min_error:\n",
    "        min_error = sum/10\n",
    "        w_opt = w_current[:]\n",
    "print(w_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking accuracy on held out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsAzKr8r5B2P",
    "outputId": "b3044844-98a7-4157-e8fe-afe20657bc92"
   },
   "outputs": [],
   "source": [
    "#accuracy on held-out validation\n",
    "y_pred = []\n",
    "for j in range(len(test_x)):\n",
    "    y_pred.append(pred(test_x[j],w_opt))\n",
    "c = acc(y_pred,test_y)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDvkMhoC7yM3"
   },
   "outputs": [],
   "source": [
    "#function to calculate f1score\n",
    "def f1score(y_pred,test_y):\n",
    "    a = np.unique(test_y)\n",
    "    #calculate the f1score for all classes\n",
    "    for k in a:\n",
    "        p_pred = np.count_nonzero(y_pred == k)\n",
    "        n_pred = np.count_nonzero(y_pred == -k)\n",
    "        p_act = np.count_nonzero(test_y == k)\n",
    "        n_act = np.count_nonzero(test_y == -k)\n",
    "        c = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i]==test_y[i] and y_pred[i]==k:\n",
    "                c = c + 1\n",
    "        t_p = c\n",
    "        c = 0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i]==test_y[i] and y_pred[i]==-k:\n",
    "                c = c + 1\n",
    "        t_n = c\n",
    "        f_p = p_pred - t_p\n",
    "        f_n = n_pred - t_n\n",
    "\n",
    "        #calcuating f1 score\n",
    "        precision = t_p/(t_p+f_p)\n",
    "        recall = t_p/(t_p+f_n)\n",
    "        f1 = 2*(precision*recall)/(precision + recall)\n",
    "        print('For class',k,f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating F1 score for both classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vR_z_xL-Fbe0",
    "outputId": "a0849781-4e94-4e05-8f1d-52864e7be4ef"
   },
   "outputs": [],
   "source": [
    "f1 = f1score(y_pred,test_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9hKNinOv5p6"
   },
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zvBoWET2sTG"
   },
   "outputs": [],
   "source": [
    "#generating data\n",
    "X = np.random.normal(10,5,50)\n",
    "X.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFkwu1WxwKOI"
   },
   "source": [
    "Q2 a) <br>\n",
    "Calulation of likelihood, posterior parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGRscZwMv-XL",
    "outputId": "8b7b8e58-f07e-445f-9282-fea2f01ce544"
   },
   "outputs": [],
   "source": [
    "#calulating likelihood mean and std\n",
    "prior_mean =25\n",
    "prior_std = 5\n",
    "std = 5 \n",
    "likelihood_mean = X.sum()/50\n",
    "likelihood_std = 5/np.sqrt(len(X))\n",
    "\n",
    "print(likelihood_mean,likelihood_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "epYbK6TbwNhr",
    "outputId": "0c9300e0-7c5c-47f8-d0ef-7c92e2ef348b"
   },
   "outputs": [],
   "source": [
    "#calculating posterior mean and std\n",
    "def post_param(X,likelihood_mean,likelihood_std,std,prior_mean,prior_std):\n",
    "    post_std = np.sqrt((1/(prior_std**2) + len(X)/(std**2)))**-1\n",
    "    post_mean = (post_std**2)*(prior_mean/(prior_std**2)+(len(X)*likelihood_mean)/std**2)\n",
    "    return post_std, post_mean\n",
    "\n",
    "\n",
    "#function for posterior mean and std\n",
    "post_std, post_mean = post_param(X,likelihood_mean,likelihood_std,std,prior_mean,prior_std)\n",
    "print(post_mean,post_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ooTE0De5wP5V",
    "outputId": "0cd9e40d-ecc1-4da0-a8d6-69a0e73ffc23"
   },
   "outputs": [],
   "source": [
    "#plotting likeihood, posterior, prior disribution\n",
    "x = np.linspace(-5,40,1000)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.xlim(5,35)\n",
    "plt.plot(x, 1/(post_std * np.sqrt(2 * np.pi)) *np.exp( - (x - post_mean)**2 / (2 * post_std**2) ),linewidth=1, color='r', label='posterior')\n",
    "plt.plot(x, 1/(likelihood_std * np.sqrt(2 * np.pi)) *np.exp( - (x - likelihood_mean)**2 / (2 * likelihood_std**2) ),linewidth=1, color='b',label = 'likelihood')\n",
    "plt.plot(x, 1/(5 * np.sqrt(2 * np.pi)) *np.exp( - (x - 25)**2 / (2 * 5**2) ),linewidth=1, color='g', label='prior')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZM39DM0wu5O"
   },
   "source": [
    "Likelihood for Normal Distribution<br>\n",
    "<b>Probabiltiy Density Funtion (PDF) of Normal distribution is </b><br>\n",
    "$\\begin{equation}f(x)  = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \n",
    "\\end{equation}$\n",
    "\n",
    "We have n i.i.d observation as $x_1,x_2,x_3,x_4....x_i$<br>\n",
    "$ \n",
    "\\begin{align}\n",
    " L(x_1,x_2,x_3..x_i|\\sigma,\\mu) &= \\prod_{i=1}^{n}  \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp \\Bigg\\{{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}} \\Bigg\\} \\\\\n",
    " &= \\Bigg( \\frac{1}{\\sigma\\sqrt{2\\pi}}  \\Bigg)^n  \n",
    " \\exp\\Bigg\\{ {-\\frac{1}{2\\sigma^2}} \\sum_{i=1}^n {(x_i-\\mu)^2}\\Bigg\\} \\\\\n",
    " &\\propto \\exp \\Bigg\\{ {-\\frac{1}{2\\sigma^2}} \\sum_{i=1}^n {(x_i-\\mu)^2}\\Bigg\\} \\\\  &= \\exp \\Bigg\\{ {-\\frac{n}{2\\sigma^2}} \\Bigg(  \\mu^2 - 2\\bar{x}\\mu +\\frac{1}{n} \n",
    " \\sum x_i^2  \\Bigg)   \\Bigg\\} \\quad \\quad ........(1)\\\\\n",
    " \\text{Also we know that Likelihood of Normal in form of } \\mu_{MLE} \\text{ and   } \\sigma_{MLE}\\\\\n",
    "&= \\Bigg( \\frac{1}{\\sigma_{MLE}\\sqrt{2\\pi}}  \\Bigg)^n  \n",
    " \\exp\\Bigg\\{ {-\\frac{1}{2\\sigma_{MLE}^2}} \\sum_{i=1}^n {(\\mu-\\mu_{MLE})^2}\\Bigg\\} \\\\\n",
    " &\\propto \\exp \\Bigg\\{ {-\\frac{1}{2\\sigma_{MLE}^2}} \\sum_{i=1}^n {(\\mu-\\mu_{MLE})^2}\\Bigg\\} \\\\\n",
    " &= \\exp \\Bigg\\{ {-\\frac{1}{2\\sigma_{MLE}^2}} \\Bigg(  \\mu^2 - 2\\mu_{MLE}\\mu + \\mu_{MLE}^2\\Bigg\\} \\quad \\quad ........(2)\\\\\n",
    " \\end{align}\\\\\n",
    " \\text{Comparing (1) and (2) we get}\\\\\n",
    " $<br>\n",
    " $$\\mu_{MLE} = \\bar{x}\\\\\n",
    " \\sigma_{MLE} = \\frac{\\sigma}{\\sqrt{n}} \\\\\n",
    " L \\sim \\mathcal{N}(\\mu_{MLE},\\,\\sigma^{2}_{MLE})$$\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hsibs4O0w0PT"
   },
   "source": [
    "Q2 b) <br>\n",
    "Metroplois algorithm and plotting its histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys5STDSmwqDw"
   },
   "outputs": [],
   "source": [
    "#probability density function \n",
    "def density(y,mean,std):\n",
    "    x = 1/(std * np.sqrt(2 * np.pi)) *np.exp( - (y - mean)**2 / (2 * std**2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7mDcgw6w3v6"
   },
   "outputs": [],
   "source": [
    "#function metropolis hastings \n",
    "def metropolis(likelihood_mean,std,prior_mean,prior_std,init_std=1,init_mean=1,converge = 1e-6):\n",
    "    p = init_mean\n",
    "    t_std = init_std\n",
    "    post = []\n",
    "    post.append(p)\n",
    "    mean = np.mean(post)\n",
    "    while True:\n",
    "        for i in range(100):\n",
    "            new_p = np.random.normal(p,t_std)\n",
    "            new_p_den = density(new_p,likelihood_mean,std)*density(new_p,prior_mean,prior_std) \n",
    "            alpha = np.random.uniform(0,1)\n",
    "            p_d = density(p,likelihood_mean,std) * density(p,prior_mean,prior_std)\n",
    "            ratio = new_p_den/p_d\n",
    "            if ratio > alpha :\n",
    "                p = new_p\n",
    "                post.append(new_p)\n",
    "            else:\n",
    "                pass\n",
    "        current = np.mean(post)\n",
    "        #convergence condtion\n",
    "        if abs(mean - current) < converge:\n",
    "           return post\n",
    "        mean = current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "A7fbmH5uw7pt",
    "outputId": "7790e74f-46af-4910-ff24-ceed7a4dabf6"
   },
   "outputs": [],
   "source": [
    "#ploting posterior distriution and samples from metropolis algorithm\n",
    "post = metropolis(likelihood_mean,likelihood_std,prior_mean,prior_std,init_std=1)\n",
    "x = np.linspace(5,15,1000)\n",
    "plt.hist(post,bins=60,density=True, label = 'samples from mcmc')\n",
    "plt.plot(x, 1/(post_std * np.sqrt(2 * np.pi)) *np.exp( - (x - post_mean)**2 / (2 * post_std**2) ),linewidth=2, color='r' , label ='posterior')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmTBhbzmxDoJ"
   },
   "source": [
    "Q2 c)\n",
    "Changes in speed of convergence as the step size changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rnwYMaQsw_IP",
    "outputId": "b5ed5655-531d-4462-a8db-c3bfd8bdc313",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for different time required for different step size\n",
    "a = [0.01,0.1,1,2,4,8,16]\n",
    "for i in a:\n",
    "    start_time = time.time()\n",
    "    post = metropolis(likelihood_mean,likelihood_std,prior_mean,prior_std,init_std=i)\n",
    "    end_time = time.time()\n",
    "    print('time for step size ',i,'-',end_time-start_time)\n",
    "    plt.plot(x, 1/(post_std * np.sqrt(2 * np.pi)) *np.exp( - (x - post_mean)**2 / (2 * post_std**2) ),linewidth=2, color='r')\n",
    "    plt.hist(post,bins=60,density=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8nA-7EsxI-A"
   },
   "source": [
    "#### Q2 c) \n",
    "For the convergence the step size should not be much large or very less it should be just right to converge quickly and also to form the proper distribution. <br>\n",
    "If the step size is very small then it take more time to converge and if step size is very large it takes somewhat similar time but does no properly forms the histrogram which should be similar to distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpzMmqinxGhH"
   },
   "outputs": [],
   "source": [
    "#updated metropolis algorithm to perform particular number of iterations\n",
    "def updated_metropolis(likelihood_mean,std,prior_mean,prior_std,init_std=1,init_mean=1,converge = 1e-6,_iter =10000 ):\n",
    "    p = init_mean\n",
    "    t_std = init_std\n",
    "    post = []\n",
    "    post.append(p)\n",
    "    count = 0\n",
    "    mean = np.mean(post)\n",
    "    while True:\n",
    "        for i in range(70):\n",
    "            count = count + 1 \n",
    "            new_p = np.random.normal(p,t_std)\n",
    "            new_p_den = density(new_p,likelihood_mean,std)*density(new_p,prior_mean,prior_std) \n",
    "            alpha = np.random.uniform(0,1)\n",
    "            p_d = density(p,likelihood_mean,std) * density(p,prior_mean,prior_std)\n",
    "            ratio = new_p_den/p_d\n",
    "            if ratio > alpha :\n",
    "                p = new_p\n",
    "                post.append(new_p)\n",
    "            else:\n",
    "                pass\n",
    "        current = np.mean(post)\n",
    "        if count > _iter:\n",
    "           return post\n",
    "        mean = current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjI9o3aGxYAM"
   },
   "source": [
    "If step size is very less and sampling is terminated to soon it never reaches the desired distirution , hence to get to convergence it will take very large time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "tb9ABkk7xXVc",
    "outputId": "79ef748a-1dc7-40c6-e8fa-a29df9f19fc3"
   },
   "outputs": [],
   "source": [
    "#here step size is considered as 0.01 and 5000 iterations\n",
    "post = updated_metropolis(likelihood_mean,likelihood_std,prior_mean,prior_std,init_std = 0.01, _iter= 10000 )\n",
    "plt.plot(x, 1/(post_std * np.sqrt(2 * np.pi)) *np.exp( - (x - post_mean)**2 / (2 * post_std**2) ),linewidth=2, color='r')\n",
    "plt.hist(post,bins=60,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrDj-FlTxffO"
   },
   "source": [
    "If step size is very large and we terminated the iteration early it will not form the proper shape of distribution for most of the time it will keep sampling the points outside the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "iePJZiVGxa2x",
    "outputId": "39843c3d-7d51-44bb-90a9-7f93421748d1"
   },
   "outputs": [],
   "source": [
    "# in this case the step size is considered as 100 and 5000 iterations\n",
    "post = updated_metropolis(likelihood_mean,likelihood_std,prior_mean,prior_std,init_std = 100, _iter= 10000 )\n",
    "plt.plot(x, 1/(post_std * np.sqrt(2 * np.pi)) *np.exp( - (x - post_mean)**2 / (2 * post_std**2) ),linewidth=2, color='r')\n",
    "plt.hist(post,bins=60,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPqFBpXhxhyX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "a33.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
